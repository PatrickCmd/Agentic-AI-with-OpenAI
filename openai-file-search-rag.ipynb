{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing RAG on PDFs using File Search in the Responses API\n",
    "\n",
    "https://cookbook.openai.com/examples/file_search_responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install PyPDF2 pandas tqdm openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import concurrent\n",
    "import PyPDF2\n",
    "import os\n",
    "import pandas as pd\n",
    "import base64\n",
    "import getpass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<openai.OpenAI at 0x10dc51b90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_pdfs = 'openai_blog_pdfs' # have those PDFs stored locally here\n",
    "pdf_files = [os.path.join(dir_pdfs, f) for f in os.listdir(dir_pdfs)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['openai_blog_pdfs/Virtual_Agent_Chatbot_using_Open_Artificial_Intelligence_Final_.pdf',\n",
       " 'openai_blog_pdfs/deep_research_blog.pdf',\n",
       " 'openai_blog_pdfs/agentic-ai-the-new-frontier-in-genai-an-executive-playbook.pdf']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Vector Store with our PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_single_pdf(file_path: str, vector_store_id: str):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    try:\n",
    "        file_response = client.files.create(file=open(file_path, 'rb'), purpose=\"assistants\")\n",
    "        attach_response = client.vector_stores.files.create(\n",
    "            vector_store_id=vector_store_id,\n",
    "            file_id=file_response.id\n",
    "        )\n",
    "        return {\"file\": file_name, \"status\": \"success\"}\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {file_name}: {str(e)}\")\n",
    "        return {\"file\": file_name, \"status\": \"failed\", \"error\": str(e)}\n",
    "\n",
    "def upload_pdf_files_to_vector_store(vector_store_id: str):\n",
    "    pdf_files = [os.path.join(dir_pdfs, f) for f in os.listdir(dir_pdfs)]\n",
    "    stats = {\"total_files\": len(pdf_files), \"successful_uploads\": 0, \"failed_uploads\": 0, \"errors\": []}\n",
    "    \n",
    "    print(f\"{len(pdf_files)} PDF files to process. Uploading in parallel...\")\n",
    "\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = {executor.submit(upload_single_pdf, file_path, vector_store_id): file_path for file_path in pdf_files}\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(pdf_files)):\n",
    "            result = future.result()\n",
    "            if result[\"status\"] == \"success\":\n",
    "                stats[\"successful_uploads\"] += 1\n",
    "            else:\n",
    "                stats[\"failed_uploads\"] += 1\n",
    "                stats[\"errors\"].append(result)\n",
    "\n",
    "    return stats\n",
    "\n",
    "def create_vector_store(store_name: str) -> dict:\n",
    "    try:\n",
    "        vector_store = client.vector_stores.create(name=store_name)\n",
    "        details = {\n",
    "            \"id\": vector_store.id,\n",
    "            \"name\": vector_store.name,\n",
    "            \"created_at\": vector_store.created_at,\n",
    "            \"file_count\": vector_store.file_counts.completed\n",
    "        }\n",
    "        print(\"Vector store created:\", details)\n",
    "        return details\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating vector store: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created: {'id': 'vs_67d1e4c26488819181015ff2bd06b2d4', 'name': 'openai_blog_store', 'created_at': 1741808834, 'file_count': 0}\n",
      "3 PDF files to process. Uploading in parallel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:13<00:00,  4.46s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_files': 3, 'successful_uploads': 3, 'failed_uploads': 0, 'errors': []}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_name = \"openai_blog_store\"\n",
    "vector_store_details = create_vector_store(store_name)\n",
    "upload_pdf_files_to_vector_store(vector_store_details[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standalone vector search\n",
    "\n",
    "[Vector Search API](https://platform.openai.com/docs/api-reference/vector-stores/search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What's Deep Research?\"\n",
    "search_results = client.vector_stores.search(\n",
    "    vector_store_id=vector_store_details['id'],\n",
    "    query=query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3487 of character of content from deep_research_blog.pdf with a relevant score of 0.980603075780475\n",
      "3378 of character of content from deep_research_blog.pdf with a relevant score of 0.9208701391312681\n",
      "3639 of character of content from deep_research_blog.pdf with a relevant score of 0.8995781351795552\n",
      "3034 of character of content from deep_research_blog.pdf with a relevant score of 0.8966293288642615\n",
      "3187 of character of content from deep_research_blog.pdf with a relevant score of 0.8354302461389134\n",
      "3300 of character of content from deep_research_blog.pdf with a relevant score of 0.7951640428186445\n",
      "3228 of character of content from deep_research_blog.pdf with a relevant score of 0.758416484494299\n",
      "2706 of character of content from deep_research_blog.pdf with a relevant score of 0.7188645402872771\n",
      "1960 of character of content from deep_research_blog.pdf with a relevant score of 0.6969411311345265\n",
      "3147 of character of content from deep_research_blog.pdf with a relevant score of 0.691387735835776\n"
     ]
    }
   ],
   "source": [
    "for result in search_results.data:\n",
    "    print(str(len(result.content[0].text)) + ' of character of content from ' + result.filename + ' with a relevant score of ' + str(result.score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating search results with LLM in a single API call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files used: {'deep_research_blog.pdf'}\n",
      "Response:\n",
      "Deep Research is an advanced capability introduced in ChatGPT by OpenAI. It functions as an agent that can autonomously conduct extensive multi-step research tasks on the internet. Here’s a summary of its features:\n",
      "\n",
      "- **Complex Research Execution**: Deep Research can synthesize information from hundreds of online sources, completing tasks in a fraction of the time it would take a human.\n",
      "\n",
      "- **Target Audience**: It's designed for professionals in fields like finance, science, and engineering, as well as consumers needing thorough, precise information for informed decisions.\n",
      "\n",
      "- **Functionality**: Users can request specific analyses or reports, and Deep Research outputs a comprehensive report complete with citations and summaries, making it easy to verify the information.\n",
      "\n",
      "- **Learning Model**: It utilizes a version of OpenAI’s upcoming model optimized for data analysis and web browsing, capable of reasoning and adapting as it processes new information.\n",
      "\n",
      "- **Limitations**: While it's designed to be efficient, it may still make mistakes, such as hallucinatory facts, and struggles with confidence calibration in its outputs.\n",
      "\n",
      "Overall, Deep Research represents a significant step towards achieving more autonomous capabilities in AI, enhancing productivity and decision-making through advanced data synthesis.\n"
     ]
    }
   ],
   "source": [
    "query = \"What's Deep Research?\"\n",
    "response = client.responses.create(\n",
    "    input= query,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_details['id']],\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Extract annotations from the response\n",
    "annotations = response.output[1].content[0].annotations\n",
    "    \n",
    "# Get top-k retrieved filenames\n",
    "retrieved_files = set([result.filename for result in annotations])\n",
    "\n",
    "print(f'Files used: {retrieved_files}')\n",
    "print('Response:')\n",
    "print(response.output[1].content[0].text) # 0 being the filesearch call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Deep Research is an advanced capability introduced in ChatGPT by OpenAI. It functions as an agent that can autonomously conduct extensive multi-step research tasks on the internet. Here’s a summary of its features:\n",
       "\n",
       "- **Complex Research Execution**: Deep Research can synthesize information from hundreds of online sources, completing tasks in a fraction of the time it would take a human.\n",
       "\n",
       "- **Target Audience**: It's designed for professionals in fields like finance, science, and engineering, as well as consumers needing thorough, precise information for informed decisions.\n",
       "\n",
       "- **Functionality**: Users can request specific analyses or reports, and Deep Research outputs a comprehensive report complete with citations and summaries, making it easy to verify the information.\n",
       "\n",
       "- **Learning Model**: It utilizes a version of OpenAI’s upcoming model optimized for data analysis and web browsing, capable of reasoning and adapting as it processes new information.\n",
       "\n",
       "- **Limitations**: While it's designed to be efficient, it may still make mistakes, such as hallucinatory facts, and struggles with confidence calibration in its outputs.\n",
       "\n",
       "Overall, Deep Research represents a significant step towards achieving more autonomous capabilities in AI, enhancing productivity and decision-making through advanced data synthesis."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(response.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files used: {'agentic-ai-the-new-frontier-in-genai-an-executive-playbook.pdf'}\n",
      "Response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Agentic AI generally refers to advanced AI systems that possess the ability to make autonomous decisions and take actions to achieve specific goals with limited or no direct human intervention. Key characteristics include:\n",
       "\n",
       "1. **Autonomy**: These systems can operate independently, making decisions based on their programming and environmental inputs.\n",
       "2. **Goal-oriented Behavior**: They are designed to pursue specific objectives and optimize actions for desired outcomes.\n",
       "3. **Environmental Interaction**: Agentic AI interacts with its surroundings, perceiving changes and adapting strategies.\n",
       "4. **Learning Capability**: Many systems use machine learning techniques to improve performance over time.\n",
       "5. **Workflow Optimization**: They enhance business processes by integrating language understanding with reasoning and decision-making.\n",
       "6. **Multi-agent Communication**: Agentic AI facilitates communication among different agents to build complex workflows.\n",
       "\n",
       "This technology is transforming various sectors such as healthcare, finance, and retail by automating routine tasks, enhancing decision-making, and improving customer experiences."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"What's Agentic AI?\"\n",
    "response = client.responses.create(\n",
    "    input= query,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_details['id']],\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Extract annotations from the response\n",
    "annotations = response.output[1].content[0].annotations\n",
    "    \n",
    "# Get top-k retrieved filenames\n",
    "retrieved_files = set([result.filename for result in annotations])\n",
    "\n",
    "print(f'Files used: {retrieved_files}')\n",
    "print('Response:')\n",
    "display(Markdown(response.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files used: {'agentic-ai-the-new-frontier-in-genai-an-executive-playbook.pdf'}\n",
      "Response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Businesses can leverage agentic AI solutions in various ways to enhance their operations and overall performance:\n",
       "\n",
       "1. **Process Automation**: Agentic AI can automate routine tasks, allowing organizations to reduce operational costs and boost efficiency. For instance, in customer service, AI can manage common inquiries, enabling human agents to focus on more complex issues.\n",
       "\n",
       "2. **Data Analysis and Insights**: These systems can analyze vast amounts of data quickly and provide actionable insights. Companies can use these insights for better decision-making, market trend prediction, and optimizing revenue and operations.\n",
       "\n",
       "3. **Enhanced Customer Experience**: AI-powered chatbots and virtual assistants can offer personalized and instant support, improving customer engagement and satisfaction. For example, e-commerce platforms often utilize AI to recommend products based on user behavior, which can lead to increased sales.\n",
       "\n",
       "4. **Service-as-a-Software Model**: This innovative model allows businesses to outsource specific tasks to AI agents, paying only for outcomes rather than software licenses or subscriptions. This approach can significantly reduce costs and enhance operational scale.\n",
       "\n",
       "5. **Agility and Responsiveness**: By automating workflows, businesses can enhance their agility, allowing them to adapt quickly to changing market demands and operational challenges.\n",
       "\n",
       "6. **Improve Decision-Making**: With real-time data analysis, agentic AI can facilitate improved decision-making processes, affecting sectors like finance and healthcare positively by streamlining operations and enhancing accuracy.\n",
       "\n",
       "7. **Integration with Existing Systems**: These AI systems can integrate seamlessly with current tools and workflows, optimizing resource allocation and enhancing communication and collaboration across an organization.\n",
       "\n",
       "8. **Ethical and Responsible Use**: Businesses should ensure their AI systems are developed and implemented ethically, considering transparency and accountability in decision-making processes.\n",
       "\n",
       "In summary, agentic AI solutions facilitate enhanced operational efficiency, better customer service, insightful data analysis, and more strategic decision-making, positioning businesses advantageously in competitive environments."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"How can businesses use agentic AI solutions for business operations?\"\n",
    "response = client.responses.create(\n",
    "    input= query,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_details['id']],\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Extract annotations from the response\n",
    "annotations = response.output[1].content[0].annotations\n",
    "    \n",
    "# Get top-k retrieved filenames\n",
    "retrieved_files = set([result.filename for result in annotations])\n",
    "\n",
    "print(f'Files used: {retrieved_files}')\n",
    "print('Response:')\n",
    "display(Markdown(response.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files used: {'Virtual_Agent_Chatbot_using_Open_Artificial_Intelligence_Final_.pdf'}\n",
      "Response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here are the definitions of the requested terms:\n",
       "\n",
       "### Generative AI\n",
       "Generative AI refers to algorithms that can generate novel content, rather than just analyzing or acting on existing data. This includes applications like text generation, image synthesis, and even code generation. Generative AI is seen as capable of exhibiting a form of creativity, pushing technology into realms previously reserved for human creativity.\n",
       "\n",
       "### LLMs (Large Language Models)\n",
       "LLMs are advanced AI models designed to understand and generate human language. They capture the structure of language through vast amounts of training data, allowing them to perform various natural language processing tasks such as text generation, translation, summarization, and sentiment analysis. Their capabilities span multiple domains, including content creation and code development.\n",
       "\n",
       "### LangChain\n",
       "LangChain is an open-source Python framework created to facilitate the development of applications powered by large language models. It provides developers with reusable components that connect language models with external data sources. Its modular architecture simplifies the integration of LLMs, allowing developers to build complex workflows, manage conversational context, and incorporate memory systems for applications like chatbots."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"Define the following terms: Generative AI, LLMs, and Langchain\"\n",
    "response = client.responses.create(\n",
    "    input= query,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_details['id']],\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Extract annotations from the response\n",
    "annotations = response.output[1].content[0].annotations\n",
    "    \n",
    "# Get top-k retrieved filenames\n",
    "retrieved_files = set([result.filename for result in annotations])\n",
    "\n",
    "print(f'Files used: {retrieved_files}')\n",
    "print('Response:')\n",
    "display(Markdown(response.output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files used: {'agentic-ai-the-new-frontier-in-genai-an-executive-playbook.pdf', 'Virtual_Agent_Chatbot_using_Open_Artificial_Intelligence_Final_.pdf'}\n",
      "Response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "To create a virtual agent (chatbot) using OpenAI, you can follow these key steps based on the relevant methods outlined in the document you provided:\n",
       "\n",
       "### 1. **Select a Framework and Libraries**\n",
       "   - Use **LangChain** as the main framework, which simplifies integration with various language models (LLMs) such as Google's Gemini Pro or OpenAI's models. It provides a modular architecture for building LLM applications.\n",
       "   - For the front-end, utilize **Streamlit**, a Python library that allows for easy creation of web applications.\n",
       "\n",
       "### 2. **Set Up Your Environment**\n",
       "   - Install the necessary packages:\n",
       "     ```bash\n",
       "     pip install streamlit langchain-google-genai\n",
       "     ```\n",
       "\n",
       "### 3. **Code Structure**\n",
       "   Create a Python script that initializes the chatbot. Here is a simplified pseudo-code:\n",
       "\n",
       "   ```python\n",
       "   import streamlit as st\n",
       "   from langchain_google_genai import ChatGoogleGenerativeAI\n",
       "\n",
       "   # Initialize the model\n",
       "   llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", google_api_key=\"YOUR_API_KEY\")\n",
       "\n",
       "   def generate_response(user_input):\n",
       "       return llm.invoke(user_input).content\n",
       "\n",
       "   def main():\n",
       "       st.title(\"Virtual Agent (Chatbot)\")\n",
       "       user_input = st.chat_input(\"Ask away!\")\n",
       "       if user_input:\n",
       "           bot_response = generate_response(user_input)\n",
       "           st.chat_message(\"assistant\").markdown(bot_response)\n",
       "\n",
       "   if __name__ == \"__main__\":\n",
       "       main()\n",
       "   ```\n",
       "\n",
       "### 4. **Handle User Input and Responses**\n",
       "   - Use Streamlit's session state to track conversation history. This way, you can maintain context across user interactions.\n",
       "   - Display previous messages and respond to user inputs in real-time.\n",
       "\n",
       "### 5. **Deploy Your Application**\n",
       "   - Streamlit allows you to deploy your app easily. You might need to deploy it using free hosting, such as Streamlit Sharing, after signing up.\n",
       "\n",
       "### 6. **Test and Iterate**\n",
       "   - Ensure that your chatbot can handle various queries and provide meaningful answers. Iterate on your design based on user feedback and performance insights.\n",
       "\n",
       "### 7. **Future Enhancements**\n",
       "   - Consider adding multimodal capabilities to handle text, images, and audio interactions in future iterations.\n",
       "   - Look into making it a decentralized application if you are concerned about privacy and data security.\n",
       "\n",
       "### Conclusion\n",
       "By leveraging frameworks like LangChain and Streamlit, you can effectively build and deploy a functional virtual agent. The use of external APIs such as Google's Gemini enhances the chatbot's capabilities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"How to build a virtual agent(chatbot) using OpenAI?\"\n",
    "response = client.responses.create(\n",
    "    input= query,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[{\n",
    "        \"type\": \"file_search\",\n",
    "        \"vector_store_ids\": [vector_store_details['id']],\n",
    "    }]\n",
    ")\n",
    "\n",
    "# Extract annotations from the response\n",
    "annotations = response.output[1].content[0].annotations\n",
    "    \n",
    "# Get top-k retrieved filenames\n",
    "retrieved_files = set([result.filename for result in annotations])\n",
    "\n",
    "print(f'Files used: {retrieved_files}')\n",
    "print('Response:')\n",
    "display(Markdown(response.output_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating performance\n",
    "#### Generating questions\n",
    "\n",
    "We will create functions that will read through the PDFs we have locally and generate a question that can only be answered by this document. Therefore it'll create our evaluation dataset that we can use after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_path, \"rb\") as f:\n",
    "            reader = PyPDF2.PdfReader(f)\n",
    "            for page in reader.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {pdf_path}: {e}\")\n",
    "    return text\n",
    "\n",
    "def generate_questions(pdf_path):\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "    prompt = (\n",
    "        \"Can you generate a question that can only be answered from this document?:\\n\"\n",
    "        f\"{text}\\n\\n\"\n",
    "    )\n",
    "\n",
    "    response = client.responses.create(\n",
    "        input=prompt,\n",
    "        model=\"gpt-4o\",\n",
    "    )\n",
    "\n",
    "    question = response.output[0].content[0].text\n",
    "\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What was the main obstacle faced by Muthana Alsaadi, Ammar Abdulzahra Alabbassi, and their team in developing their virtual agent (chatbot) project, and how did they overcome it?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_questions(pdf_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now generate all the questions for all the PDFs we've got stored locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate questions for each PDF and store in a dictionary\n",
    "questions_dict = {}\n",
    "for pdf_path in pdf_files:\n",
    "    questions = generate_questions(pdf_path)\n",
    "    questions_dict[os.path.basename(pdf_path)] = questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Virtual_Agent_Chatbot_using_Open_Artificial_Intelligence_Final_.pdf': 'What major obstacle did the authors face when trying to use Microsoft Azure services for their chatbot project in Iraq?',\n",
       " 'deep_research_blog.pdf': 'What is the name of the newly launched agentic capability in ChatGPT mentioned in this document?',\n",
       " 'agentic-ai-the-new-frontier-in-genai-an-executive-playbook.pdf': 'What are the phases of evolution for agentic frameworks as outlined in the document?'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll convert our dictionary into a dataframe and process it using gpt-4o-mini. We will look out for the expected file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for filename, query in questions_dict.items():\n",
    "    rows.append({\"query\": query, \"_id\": filename.replace(\".pdf\", \"\")})\n",
    "\n",
    "# Metrics evaluation parameters\n",
    "k = 5\n",
    "total_queries = len(rows)\n",
    "correct_retrievals_at_k = 0\n",
    "reciprocal_ranks = []\n",
    "average_precisions = []\n",
    "\n",
    "def process_query(row):\n",
    "    query = row['query']\n",
    "    expected_filename = row['_id'] + '.pdf'\n",
    "    # Call file_search via Responses API\n",
    "    response = client.responses.create(\n",
    "        input=query,\n",
    "        model=\"gpt-4o-mini\",\n",
    "        tools=[{\n",
    "            \"type\": \"file_search\",\n",
    "            \"vector_store_ids\": [vector_store_details['id']],\n",
    "            \"max_num_results\": k,\n",
    "        }],\n",
    "        tool_choice=\"required\" # it will force the file_search, while not necessary, it's better to enforce it as this is what we're testing\n",
    "    )\n",
    "    # Extract annotations from the response\n",
    "    annotations = None\n",
    "    if hasattr(response.output[1], 'content') and response.output[1].content:\n",
    "        annotations = response.output[1].content[0].annotations\n",
    "    elif hasattr(response.output[1], 'annotations'):\n",
    "        annotations = response.output[1].annotations\n",
    "\n",
    "    if annotations is None:\n",
    "        print(f\"No annotations for query: {query}\")\n",
    "        return False, 0, 0\n",
    "\n",
    "    # Get top-k retrieved filenames\n",
    "    retrieved_files = [result.filename for result in annotations[:k]]\n",
    "    if expected_filename in retrieved_files:\n",
    "        rank = retrieved_files.index(expected_filename) + 1\n",
    "        rr = 1 / rank\n",
    "        correct = True\n",
    "    else:\n",
    "        rr = 0\n",
    "        correct = False\n",
    "\n",
    "    # Calculate Average Precision\n",
    "    precisions = []\n",
    "    num_relevant = 0\n",
    "    for i, fname in enumerate(retrieved_files):\n",
    "        if fname == expected_filename:\n",
    "            num_relevant += 1\n",
    "            precisions.append(num_relevant / (i + 1))\n",
    "    avg_precision = sum(precisions) / len(precisions) if precisions else 0\n",
    "    \n",
    "    if expected_filename not in retrieved_files:\n",
    "        print(\"Expected file NOT found in the retrieved files!\")\n",
    "        \n",
    "    if retrieved_files and retrieved_files[0] != expected_filename:\n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"Expected file: {expected_filename}\")\n",
    "        print(f\"First retrieved file: {retrieved_files[0]}\")\n",
    "        print(f\"Retrieved files: {retrieved_files}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    \n",
    "    return correct, rr, avg_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 1.0, 1.0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_query(rows[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall & Precision are at 1 for this example, and our file ranked first so we're having a MRR and MAP = 1 on this example.\n",
    "\n",
    "We can now execute this processing on our set of questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:07<00:00,  2.51s/it]\n"
     ]
    }
   ],
   "source": [
    "with ThreadPoolExecutor() as executor:\n",
    "    results = list(tqdm(executor.map(process_query, rows), total=total_queries))\n",
    "\n",
    "correct_retrievals_at_k = 0\n",
    "reciprocal_ranks = []\n",
    "average_precisions = []\n",
    "\n",
    "for correct, rr, avg_precision in results:\n",
    "    if correct:\n",
    "        correct_retrievals_at_k += 1\n",
    "    reciprocal_ranks.append(rr)\n",
    "    average_precisions.append(avg_precision)\n",
    "\n",
    "recall_at_k = correct_retrievals_at_k / total_queries\n",
    "precision_at_k = recall_at_k  # In this context, same as recall\n",
    "mrr = sum(reciprocal_ranks) / total_queries\n",
    "map_score = sum(average_precisions) / total_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics at k=5:\n",
      "Recall@5: 1.0000\n",
      "Precision@5: 1.0000\n",
      "Mean Reciprocal Rank (MRR): 1.0000\n",
      "Mean Average Precision (MAP): 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Print the metrics with k\n",
    "print(f\"Metrics at k={k}:\")\n",
    "print(f\"Recall@{k}: {recall_at_k:.4f}\")\n",
    "print(f\"Precision@{k}: {precision_at_k:.4f}\")\n",
    "print(f\"Mean Reciprocal Rank (MRR): {mrr:.4f}\")\n",
    "print(f\"Mean Average Precision (MAP): {map_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
